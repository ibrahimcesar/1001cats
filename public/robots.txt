# 1001 Schr√∂dinger's Cats - robots.txt
# A Discordian blog on science, philosophy, life, the universe, and everything

# Allow all bots to crawl everything
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://1001cats.org/sitemap-index.xml
Sitemap: https://1001cats.org/sitemap-0.xml

# Specific bot directives
# Allow all major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

User-agent: DuckDuckBot
Allow: /

# Crawl delay for polite crawling
Crawl-delay: 1

# Block AI training bots
User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: CCBot
Disallow: /

# User-agent: anthropic-ai
Disallow: /

# User-agent: Claude-Web
# Disallow: /

# Block common bad bots

#User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: MJ12bot
Disallow: /

# Pagefind search index (allow crawling)
User-agent: *
Allow: /pagefind/

# Note: All statements are true in some sense, false in some sense,
# meaningless in some sense... including this robots.txt file.
# - A Discordian Directive
